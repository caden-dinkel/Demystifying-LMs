Massive Data Stage:

The first stage is, well, exactly what it sounds like. The model is in a sense ‘let loose’ on an enormous data set, containing essentially every webpage, article, book, and more. With this massive data set the model will start to learn the rules of language and its base world knowledge. During this learning process as the model is consuming endless amounts of text, the only aspect the model is looking for is the statistical probability for completing sentences. This where the model learns that “The fat cat… “ is statistically followed by “sat” and not “brick”
